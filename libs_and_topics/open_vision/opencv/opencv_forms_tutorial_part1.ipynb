{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0ae1c85314d21d2cce47ec19e8bfd2e1f3ebe6db637a00b7d0c23442c99ab12c3",
   "display_name": "Python 3.9.5 64-bit ('tf2.5': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source\n",
    "# https://www.youtube.com/watch?v=W9oRTI6mLnU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to command in windows installation - > not needed if installed with pip\n",
    "# pytesseract.pytesseract.tesseract_cmd = path/to/exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# print image\n",
    "imgQ = cv2.imread('Query.png')\n",
    "cv2.imshow(\"Output\", imgQ)\n",
    "cv2.waitKey(0) # = is the time to wait to show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1025, 785, 3)\n"
     ]
    }
   ],
   "source": [
    "# get image attributes height, width and (channel) - color depth maybe\n",
    "h, w, c = imgQ.shape\n",
    "print(imgQ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(341, 261, 3)\n"
     ]
    }
   ],
   "source": [
    "# resize image to a third\n",
    "imgQ = cv2.resize(imgQ, (w//3, h//3))\n",
    "print(imgQ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<ORB 000002F6C7EDD670>\n"
     ]
    }
   ],
   "source": [
    "# create detector - ORB\n",
    "# define features - default 500 and we change to 1000\n",
    "orb = cv2.ORB_create(1000)\n",
    "print(orb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keypoints that are unique points in the image and descriptors that are how the computer interprets them\n",
    "kp1, des1 = orb.detectAndCompute(imgQ, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# display kp1 image\n",
    "imgKp1 = cv2.drawKeypoints(imgQ, kp1, None)\n",
    "cv2.imshow(\"KeyPointsQuery\", imgKp1)\n",
    "cv2.waitKey(0) # = is the time to wait to show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# example with 5000 keypoints\n",
    "orb = cv2.ORB_create(5000)\n",
    "kp2, des2 = orb.detectAndCompute(imgQ, None)\n",
    "imgKp2 = cv2.drawKeypoints(imgQ, kp2, None)\n",
    "cv2.imshow(\"KeyPointsQuery\", imgKp2)\n",
    "cv2.waitKey(0) # = is the time to wait to show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Test(1).png', 'Test(2).png', 'Test(3).png']\n"
     ]
    }
   ],
   "source": [
    "# set path for test images\n",
    "path = \"UserForms\"\n",
    "myPicList = os.listdir(path)\n",
    "print(myPicList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print images with index number\n",
    "for j, y in enumerate(myPicList):\n",
    "    img = cv2.imread(path + \"/\" + y )\n",
    "    # img = cv2.resize(imgQ, (w//3, h//3))\n",
    "    cv2.imshow(y, img)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match keypoints\n",
    "# bf is brute force\n",
    "percent =25 # we will get the 25% best matches\n",
    "\n",
    "for j, y in enumerate(myPicList):\n",
    "    img = cv2.imread(path + \"/\" + y )\n",
    "    kp2, des2 = orb.detectAndCompute(img, None) # we will rewrite or reuse the variables from the example above to keep consistency with the tutorial\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    matches = bf.match(des2, des1)\n",
    "    # sort matches based on distance\n",
    "    matches.sort(key = lambda x: x.distance)\n",
    "    # extraxt the best matches\n",
    "    good = matches[:int(len(matches)*(percent/100))]\n",
    "    # draw marches\n",
    "    imgMatch = cv2.drawMatches(img, kp2, imgQ, kp1, good, None, flags = 2) # None is out image, flag is \n",
    "    # show images\n",
    "    cv2.imshow(y, imgMatch)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find relationship between keypoints from source and test files\n",
    "percent =25 # we will get the 25% best matches\n",
    "\n",
    "for j, y in enumerate(myPicList):\n",
    "    img = cv2.imread(path + \"/\" + y )\n",
    "    kp2, des2 = orb.detectAndCompute(img, None) # we will rewrite or reuse the variables from the example above to keep consistency with the tutorial\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    matches = bf.match(des2, des1)\n",
    "    # sort matches based on distance\n",
    "    matches.sort(key = lambda x: x.distance)\n",
    "    # extraxt the best matches\n",
    "    good = matches[:int(len(matches)*(percent/100))]\n",
    "    # draw marches\n",
    "    imgMatch = cv2.drawMatches(img, kp2, imgQ, kp1, good, None, flags = 2) # None is out image, flag is \n",
    "\n",
    "    # find relationship between keypoints from source and test files\n",
    "    srcPoints = np.float32([kp2[m.queryIdx].pt for m in good]).reshape(-1, 1, 2) # source points\n",
    "    dstPoints = np.float32([kp1[m.trainIdx].pt for m in good]).reshape(-1, 1, 2) # destination points\n",
    "    M, _ = cv2.findHomography(srcPoints, dstPoints, cv2.RANSAC, 5.0) # 5.0 is a parameter default from documentation\n",
    "    # align form\n",
    "    imgScan = cv2.warpPerspective(img, M, (w, h))\n",
    "    # show images\n",
    "    cv2.imshow(y, imgScan)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}