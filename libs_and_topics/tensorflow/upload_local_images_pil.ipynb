{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0ae1c85314d21d2cce47ec19e8bfd2e1f3ebe6db637a00b7d0c23442c99ab12c3",
   "display_name": "Python 3.7.0 64-bit ('tf2.5': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source \n",
    "# https://towardsdatascience.com/loading-custom-image-dataset-for-deep-learning-models-part-1-d64fa7aaeca6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding additional library for loading image dataset using PIL\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the image data and the labels from the images in the folder using PIL\n",
    "# In the function below\n",
    "\n",
    "#     The source folder is the input parameter containing the images for different classes.\n",
    "#     Open the image file from the folder using PIL.\n",
    "#     Resize the image based on the input dimension required for the model\n",
    "#     Convert the image to a Numpy array with float32 as the datatype\n",
    "#     Normalize the image array for faster convergence.\n",
    "\n",
    "def create_dataset_PIL(img_folder):\n",
    "    \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "       \n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= np.array(Image.open(image_path))\n",
    "            image= np.resize(image,(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "            image = image.astype('float32')\n",
    "            image /= 255  \n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    return img_data_array , class_name\n",
    "    \n",
    "PIL_img_data, class_name=create_dataset_PIL(img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting text labels to numeric codes\n",
    "# Following is the same code that we used for CV2\n",
    "\n",
    "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
    "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and compiling a simple Deep Learning Model\n",
    "\n",
    "model=tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(6)\n",
    "        ])encoder.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We finally fit our dataset to train the model. We can use Numpy array as the input\n",
    "\n",
    "history = model.fit(x=np.array(PIL_img_data, np.float32), y=np.array(list(map(int,target_val)), np.float32), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also convert the input data to tensors to train the model by using tf.cast()\n",
    "\n",
    "history = model.fit(x=tf.cast(np.array(PIL_img_data), tf.float64), y=tf.cast(list(map(int,target_val)),tf.int32), epochs=5)"
   ]
  }
 ]
}